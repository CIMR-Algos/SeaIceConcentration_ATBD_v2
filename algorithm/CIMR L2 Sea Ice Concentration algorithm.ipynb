{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4900cf0",
   "metadata": {},
   "source": [
    "# A Level-2 Sea Ice Concentration (SIC3H) algorithm for CIMR\n",
    "\n",
    "This notebook implements a prototype for a Level-2 SIC3H algorithm for the CIMR mission.\n",
    "\n",
    "We refer to the corresponding [ATBD](https://cimr-algos.github.io/SeaIceConcentration_ATBD/intro.html) and especially the [Baseline Algorithm Definition](https://cimr-algos.github.io/SeaIceConcentration_ATBD/baseline_algorithm_definition.html#baseline-algorithm-definition).\n",
    "\n",
    "In particular, the figure below illustrates the overall concept of the processing:\n",
    "<img src=\"https://cimr-algos.github.io/SeaIceConcentration_ATBD/_images/SIC_concept_diagram.png\" width=\"75%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6638d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import cmocean\n",
    "\n",
    "# local modules contain software code that implement the SIC algorithm\n",
    "from sirrdp import rrdp_file\n",
    "from pmr_sic import tiepoints as tp\n",
    "from pmr_sic import algo as sic_algo\n",
    "from pmr_sic import hybrid_algo\n",
    "\n",
    "# prototype re-gridding toolbox to handle the L1B input\n",
    "if '/home/thomasl/Work/DEVALGO/Tools/' not in sys.path:\n",
    "    sys.path.insert(0, '/home/thomasl/Work/DEVALGO/Tools/')\n",
    "from tools import io_handler as io\n",
    "from tools import collocation as coll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af12372f",
   "metadata": {},
   "source": [
    "## Parametrize the run\n",
    "\n",
    "Here we decide on some values that yield for the whole notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df80c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrdp_dir = './sirrdp'\n",
    "area = 'nh'\n",
    "algos = dict()\n",
    "algos['CKA'] = {'channels':('tb06v', 'tb37v', 'tb37h'), 'target_band':'C'}\n",
    "algos['KUKA'] = {'channels':('tb19v', 'tb37v', 'tb37h'), 'target_band':'KU'}\n",
    "algos['KA'] = {'channels':('tb37v', 'tb37h'),  'target_band':'KA'}\n",
    "\n",
    "# Change location where you stored the L1B file\n",
    "l1b_path = '/home/thomasl/Documents/DEVALGO/Simul_L1B_20230421/'\n",
    "# DEVALGO's simulated geometric test card\n",
    "l1b_fn = 'W_PT-DME-Lisbon-SAT-CIMR-1B_C_DME_20230417T105425_LD_20280110T114800_20280110T115700_TN.nc'\n",
    "# DEVALGO's simulated radiometric test card\n",
    "l1b_fn = 'W_PT-DME-Lisbon-SAT-CIMR-1B_C_DME_20230420T103323_LD_20280110T114800_20280110T115700_TN.nc'\n",
    "proj = 'nh'\n",
    "\n",
    "l1b_fn = os.path.join(l1b_path,l1b_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c3c05",
   "metadata": {},
   "source": [
    "## Off-line preparation : Tune the SIC algorithms\n",
    "\n",
    "The SIC algorithms `CKA`, `KUKA`, and `KA` require tuning before they can be run to compute SIC. The tuning step involves the preparation of the OW (Open Water, 0% SIC) and CI (Consolidated Ice, 100% SIC) tie-points, as well as the optimization of the algorithm parameters, to fit the training data best.\n",
    "\n",
    "In this implementation of the algorithm, the training data are taken from the ESA CCI Sea Ice Concentration Round Robin Data Package of Pedersen et al. (2019). The relevant data files as well as routines to parse the files are stored in module `siddrp/`.\n",
    "\n",
    "Pedersen, Leif Toudal; Saldo, Roberto; Ivanova, Natalia; Kern, Stefan; Heygster, Georg; Tonboe, Rasmus; et al. (2019): Reference dataset for sea ice concentration. figshare. Dataset. https://doi.org/10.6084/m9.figshare.6626549.v7\n",
    "\n",
    "In an operational setup, this tuning should happen approximately every day and be based on dynamically loaded TB data (e.g. over the last 7 days). This does not need to run again for each new incoming L1B file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e62af",
   "metadata": {},
   "source": [
    "### Load the OW and CI training data (from ESA CCI RRDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8a754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OW samples:  15955\n"
     ]
    }
   ],
   "source": [
    "reload(rrdp_file)\n",
    "ow_files, ci_files = rrdp_file.find_rrdp_files(rrdp_dir, area=area, years=(2007, 2013, 2018))\n",
    "\n",
    "channels_needed = []\n",
    "for alg in algos.keys():\n",
    "    channels_needed += algos[alg]['channels']\n",
    "channels_needed = set(channels_needed)\n",
    "\n",
    "rrdp_pos = rrdp_file.read_RRDP_files(area, ow_files, ci_files, channels=channels_needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c24273",
   "metadata": {},
   "source": [
    "Transfer the training data in a tie-point object. This involves some processing, like computing the tie-points and their covariance matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ow_tp = tp.OWTiepoint(source='rrdp', tbs=rrdp_pos['ow'])\n",
    "ci_tp = tp.CICETiepoint(source='rrdp', tbs=rrdp_pos['ci'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828b35c",
   "metadata": {},
   "source": [
    "### Tune the CKA, KUKA, and KA algorithms on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in algos.keys():\n",
    "    print(\"Tune {}\".format(alg,))\n",
    "    algos[alg]['algo'] = hybrid_algo.HybridSICAlgo(algos[alg]['channels'], ow_tp, ci_tp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9806d97",
   "metadata": {},
   "source": [
    "## Step 1: Load the L1B files and prepare remapped TB arrays for each algo\n",
    "\n",
    "The three algorithms `CKA`, `KUKA`, and `KA` combine different microwave channels (e.g. `CKA` combines C-Vpol, KA-Vpol, and KA-Hpol). Since each frequency channel is not sampled at the same location nor resolution, we must prepare location-matched, resolution-matched TB arrays for each algorithm.\n",
    "\n",
    "In this version of the algorithm, we prepare TB arrays at the spatial resolution of the coarsest channel (e.g. we prepare C-Vpol, KA-Vpol, and KA-Hpol to the resolution of C-Vpol as input to the `CKA` algorithm).\n",
    "\n",
    "This remapping is handled by software in the `Tools/` repository (a prototype CIMR Regridding Toolbox developed in the CIMR DEVALGO study)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global definitions\n",
    "tb_dict = {'tb01':'L','tb06':'C','tb10':'X','tb19':'KU','tb37':'KA',}\n",
    "rev_tb_dict = {v:k for k,v in tb_dict.items()}\n",
    "bands_needed = []\n",
    "for alg in algos.keys():\n",
    "    bands_needed += algos[alg]['channels']\n",
    "bands_needed = list(set([tb_dict[b[:-1]] for b in bands_needed]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ebcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read L1B. We only read the bands needed for the three algorithms\n",
    "reload(io)\n",
    "full_l1b = io.CIMR_L1B(l1b_fn, selected_bands=bands_needed, keep_calibration_view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a323440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align scalines using the scan angle offset\n",
    "full_l1b.align_arrays_to_start_at_zero_scan_angle()\n",
    "\n",
    "# coarsen l1b samples along the scanlines with a kernel of 5 (horns are *not* combined)\n",
    "coarsen_l1b = full_l1b.coarsen_along_scanlines(kernel=5)\n",
    "\n",
    "# split into forward / backward scan\n",
    "fwd_l1b, bck_l1b = coarsen_l1b.split_forward_backward_scans(method='horn_scan_angle')\n",
    "\n",
    "# reshape by interleaving the feeds \n",
    "reshaped_fwd_l1b = fwd_l1b.reshape_interleave_feed()\n",
    "reshaped_bck_l1b = bck_l1b.reshape_interleave_feed()\n",
    "\n",
    "# Collocate the channels with a nearest neighbour approach. This step covers both the\n",
    "#   definition of the target grid, and the remapping. Use the correct 'target_band' for\n",
    "#   each algorithm.\n",
    "fwd_l1x = dict()\n",
    "bck_l1x = dict()\n",
    "for alg in algos.keys():\n",
    "    fwd_l1x[alg] = coll.collocate_channels(reshaped_fwd_l1b.data, algos[alg]['target_band'], method='nn')\n",
    "    bck_l1x[alg] = coll.collocate_channels(reshaped_bck_l1b.data, algos[alg]['target_band'], method='nn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd71312",
   "metadata": {},
   "source": [
    "## Step 2: Apply the 3 algos to compute intermediate SICs\n",
    "\n",
    "This applies the three algorithms on their respective TB arrays (obtained from the L1B remapping of the TBs). The SIC algorithms are applied separately for the forward and backward scan of the swath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_res = dict()\n",
    "bck_res = dict()\n",
    "for alg in algos.keys():\n",
    "    \n",
    "    # prepare TBs in the structure expected as input to the algorithm\n",
    "    fwd_tbs = dict()\n",
    "    bck_tbs = dict()\n",
    "    for ch in algos[alg]['channels']:\n",
    "        band = tb_dict[ch[:-1]] + '_BAND'\n",
    "        varn = 'brightness_temperature_'+ch[-1]\n",
    "        fwd_tbs[ch] = fwd_l1x[alg][band][varn].values\n",
    "        bck_tbs[ch] = bck_l1x[alg][band][varn].values\n",
    "    \n",
    "    # run the algorithm to compute SIC\n",
    "    fwd_res[alg] = algos[alg]['algo'].compute_sic(fwd_tbs)\n",
    "    bck_res[alg] = algos[alg]['algo'].compute_sic(bck_tbs)\n",
    "    \n",
    "    # Simple visualization in swath L1X geometry\n",
    "\n",
    "    cmap = cmocean.cm.ice\n",
    "    ucmap = cmocean.cm.thermal\n",
    "    vmin, vmax = (0, 1)\n",
    "    umin, umax = (0, 10)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30,16))\n",
    "    axF = fig.add_subplot(1,4,1)\n",
    "    cF = axF.imshow(fwd_res[alg].sic, vmin=vmin, vmax=vmax, interpolation = 'none', origin='lower', cmap=cmap)\n",
    "    axF.set_title(alg + \" \" + \"FWD\" + \" \" + \"SIC\")\n",
    "    plt.colorbar(cF,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1,4,2, sharex=axF, sharey=axF)\n",
    "    uF = ax.imshow(fwd_res[alg].sdev, vmin=umin, vmax=umax, interpolation = 'none', origin='lower', cmap=ucmap)\n",
    "    ax.set_title(alg + \" \" + \"FWD\" + \" \" + \"SDEV\")\n",
    "    plt.colorbar(uF,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n",
    "    axB = fig.add_subplot(1,4,3)\n",
    "    cB = axB.imshow(bck_res[alg].sic, vmin=vmin, vmax=vmax, interpolation = 'none', origin='lower', cmap=cmap)\n",
    "    axB.set_title(alg + \" \" + \"BCK\" + \" \" + \"SIC\")\n",
    "    plt.colorbar(cB,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1,4,4, sharex=axB, sharey=axB)\n",
    "    uB=ax.imshow(bck_res[alg].sdev, vmin=umin, vmax=umax, interpolation = 'none', origin='lower', cmap=ucmap)\n",
    "    ax.set_title(alg + \" \" + \"BCK\" + \" \" + \"SDEV\")\n",
    "    plt.colorbar(uB,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb32e75",
   "metadata": {},
   "source": [
    "From the images above, it is clear that the three algorithms see high and low concentrations in the same locations in the Test Card, which means they are returning related SIC fields that we can later combine. The uncertainties (SDEV) are as expected lower for `CKA` than for `KUKA` that are lower than those of `KA`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf0242",
   "metadata": {},
   "source": [
    "## Step 3 : Pan-sharpening and computation of \"final\" Level-2 SIC\n",
    "\n",
    "The third step deploys a pan-sharpening methodology to combine pairs of intermediate SICs into the final Level-2 SICs. In our case, the ‘base’ image can be the high-accuracy / coarse-resolution intermediate SIC from `CKA` and the ‘sharpener’ image can be the low-accuracy / fine-resolution intermediate SIC from `KA`. This results in a final SIC named `CKA@KA`.\n",
    "\n",
    "The ATBD calls for more such pan-sharpening to happen, but for the time being we focus on `CKA@KA`.\n",
    "\n",
    "The pansharpening equation is simply\n",
    "$$\n",
    "\\begin{array}{lc}\n",
    "C_{ER} &=& \\textrm{Remap}_{HR}(C_{LR}) +  \\Delta_{edges} \\\\\n",
    "       &=& \\textrm{Remap}_{HR}(C_{LR}) + ( C_{HR} - C_{HR, blurred} ) \\\\ \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where suffix \"ER\" refers to enhanced resolution (the final SIC), \"LR\" to \"low resolution\" (the 'base' SIC to be pan-sharpened),\n",
    "and \"HR\" to \"high resolution\" (the 'sharpener' SIC). The equation also involves $C_{HR, blurred}$ which is C_{HR} blurred to\n",
    "the spatial resolution of $C_{LR}$. The quantity $( C_{HR} - C_{HR, blurred})$ is sometimes referred to as a $\\Delta_{edges}$ as it takes\n",
    "small values everywhere but in the regions where $C_{HR}$ exhibits sharp gradients (e.g. in the Marginal Ice Zone). The $\\textrm{Remap}_{HR}$ operator\n",
    "remaps the location (only the location, not the resolution) of $C_{LR}$ to those of $C_{HR}$ to enable adding the two fields together. The resulting SIC field, $C_{ER}$ is\n",
    "thus at the locations of $C_{HR}$, with the spatial resolution of $C_{HR}$ and the accuracy of $C_{LR}$ (if the pan-sharpening works perfectly).\n",
    "\n",
    "There are thus 3 steps for building the pan-sharpened SIC $C_{ER}$:\n",
    "1. Regrid 'base' SIC (coarse resolution) to 'sharpener' SIC (high resolution) grid\n",
    "2. Prepare the 'blurred' sharpener SIC field\n",
    "3. Compute $\\Delta_{edges}$ and finally $C_{ER}$\n",
    "\n",
    "\n",
    "### Step 3.1 Regrid 'base' SIC (coarse resolution) to 'sharpener' SIC (high resolution) grid \n",
    "A first intermediate step is to have the base SIC field (e.g. `CKA`) on the same grid as the sharpener grid `KA`. For this we use some of our collocation tools in the toolbox. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'CKA@KA'\n",
    "base, sharpener = algo.split('@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(coll)\n",
    "# extract target and source geometries\n",
    "fwd_trg_lon = fwd_l1x[sharpener]['geolocation']['lon'].to_numpy()\n",
    "fwd_trg_lat = fwd_l1x[sharpener]['geolocation']['lat'].to_numpy()\n",
    "fwd_src_lon = fwd_l1x[base]['geolocation']['lon'].to_numpy()\n",
    "fwd_src_lat = fwd_l1x[base]['geolocation']['lat'].to_numpy()\n",
    "bck_trg_lon = bck_l1x[sharpener]['geolocation']['lon'].to_numpy()\n",
    "bck_trg_lat = bck_l1x[sharpener]['geolocation']['lat'].to_numpy()\n",
    "bck_src_lon = bck_l1x[base]['geolocation']['lon'].to_numpy()\n",
    "bck_src_lat = bck_l1x[base]['geolocation']['lat'].to_numpy()\n",
    "# Prepare a stack of the data to be regridded (e.g. SIC and SDEV)\n",
    "what = ('sic','sdev','dal','owf')\n",
    "fwd_stack_shape = tuple(list(fwd_src_lat.shape) + [len(what),])\n",
    "bck_stack_shape = tuple(list(bck_src_lat.shape) + [len(what),])\n",
    "fwd_src_stack = np.empty(fwd_stack_shape)\n",
    "bck_src_stack = np.empty(bck_stack_shape)\n",
    "for iw, w in enumerate(what):\n",
    "    fwd_src_stack[...,iw] = fwd_res[base].get(w)\n",
    "    bck_src_stack[...,iw] = bck_res[base].get(w)\n",
    "\n",
    "# regrid and get _bAs (base @ sharpener grid), \n",
    "_fwd_bAs = coll._regrid_fields(fwd_trg_lon, fwd_trg_lat, fwd_src_lon, fwd_src_lat, fwd_src_stack)\n",
    "_bck_bAs = coll._regrid_fields(bck_trg_lon, bck_trg_lat, bck_src_lon, bck_src_lat, bck_src_stack)\n",
    "\n",
    "# store in an object\n",
    "fwd_res[algo + '(bAs)'] = sic_algo.SICAlgoResult(_fwd_bAs[...,0], _fwd_bAs[...,1], _fwd_bAs[...,2], _fwd_bAs[...,3])\n",
    "bck_res[algo + '(bAs)'] = sic_algo.SICAlgoResult(_bck_bAs[...,0], _bck_bAs[...,1], _bck_bAs[...,2], _bck_bAs[...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bAs now has the same shape as the sharpener\n",
    "assert(fwd_res[sharpener].sic.shape == fwd_res[algo+'(bAs)'].sic.shape)\n",
    "assert(bck_res[sharpener].sic.shape == bck_res[algo+'(bAs)'].sic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5f77f",
   "metadata": {},
   "source": [
    "### Step 3.2 Prepare the 'blurred' sharpener SIC field \n",
    "\n",
    "Second intermediate step is to prepare a blurred version of the sharpener SIC field, keeping it in its own grid (each grid point in the blurred SIC field is computed from the surrounding pixels in the field). The aim is to blur the 'sharpener' SIC until a resolution similar to that of the 'base' SIC (but to stay in the 'sharpener' grid).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(coll)\n",
    "\n",
    "# extract target and source geometries (the same: we stay in the sharpener's grid)\n",
    "fwd_trg_lon = fwd_l1x[sharpener]['geolocation']['lon'].to_numpy()\n",
    "fwd_trg_lat = fwd_l1x[sharpener]['geolocation']['lat'].to_numpy()\n",
    "fwd_src_lon = fwd_l1x[sharpener]['geolocation']['lon'].to_numpy()\n",
    "fwd_src_lat = fwd_l1x[sharpener]['geolocation']['lat'].to_numpy()\n",
    "bck_trg_lon = bck_l1x[sharpener]['geolocation']['lon'].to_numpy()\n",
    "bck_trg_lat = bck_l1x[sharpener]['geolocation']['lat'].to_numpy()\n",
    "bck_src_lon = bck_l1x[sharpener]['geolocation']['lon'].to_numpy()\n",
    "bck_src_lat = bck_l1x[sharpener]['geolocation']['lat'].to_numpy()\n",
    "# Prepare a stack of the data to be regridded (only the SIC)\n",
    "what = ('sic',)\n",
    "fwd_stack_shape = tuple(list(fwd_src_lat.shape) + [len(what),])\n",
    "bck_stack_shape = tuple(list(bck_src_lat.shape) + [len(what),])\n",
    "fwd_src_stack = np.empty(fwd_stack_shape)\n",
    "bck_src_stack = np.empty(bck_stack_shape)\n",
    "for iw, w in enumerate(what):\n",
    "    fwd_src_stack[...,iw] = fwd_res[sharpener].get(w)\n",
    "    bck_src_stack[...,iw] = bck_res[sharpener].get(w)\n",
    "\n",
    "# regrid and get _sbl (sharpener blurred)\n",
    "params = {'method':'gauss', 'sigmas':25000, 'neighbours':55}\n",
    "_fwd_sbl = coll._regrid_fields(fwd_trg_lon, fwd_trg_lat, fwd_src_lon, fwd_src_lat, fwd_src_stack, params=params)\n",
    "_bck_sbl = coll._regrid_fields(bck_trg_lon, bck_trg_lat, bck_src_lon, bck_src_lat, bck_src_stack, params=params)\n",
    "\n",
    "\n",
    "# store in an object\n",
    "fwd_res[algo + '(blur)'] = sic_algo.SICAlgoResult(_fwd_sbl[...,0], fwd_res[sharpener].sdev, fwd_res[sharpener].dal, fwd_res[sharpener].owf)\n",
    "bck_res[algo + '(blur)'] = sic_algo.SICAlgoResult(_bck_sbl[...,0], bck_res[sharpener].sdev, bck_res[sharpener].dal, bck_res[sharpener].owf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a83f1",
   "metadata": {},
   "source": [
    "### Step 3.3 Compute $\\Delta_{edges}$ and finally $C_{ER}$\n",
    "\n",
    "This is the final step of the pan-sharpening. We first compute $\\Delta_{edges} = C_{HR} - C_{HR, blurred}$, then the final enhance-resolution SIC $C_{ER}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the delta edges\n",
    "_fwd_delta = fwd_res[sharpener].sic - fwd_res[algo + '(blur)'].sic\n",
    "_bck_delta = bck_res[sharpener].sic - bck_res[algo + '(blur)'].sic\n",
    "\n",
    "# store in an object (intermediate result, we store it only for visualization in the notebook)\n",
    "_fwd_zeros = np.zeros_like(_fwd_delta)\n",
    "_bck_zeros = np.zeros_like(_bck_delta)\n",
    "fwd_res[algo + '(delta)'] = sic_algo.SICAlgoResult(_fwd_delta, _fwd_zeros, _fwd_zeros, _fwd_zeros)\n",
    "bck_res[algo + '(delta)'] = sic_algo.SICAlgoResult(_bck_delta, _bck_zeros, _bck_zeros, _bck_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final pan-sharpened SIC\n",
    "_fwd_er = fwd_res[algo+'(bAs)'].sic + _fwd_delta\n",
    "_bck_er = bck_res[algo+'(bAs)'].sic + _bck_delta\n",
    "\n",
    "# store in an object\n",
    "_fwd_zeros = np.zeros_like(_fwd_delta)\n",
    "_bck_zeros = np.zeros_like(_bck_delta)\n",
    "fwd_res[algo] = sic_algo.SICAlgoResult(_fwd_er, fwd_res[algo+'(bAs)'].sdev, _fwd_zeros, _fwd_zeros)\n",
    "bck_res[algo] = sic_algo.SICAlgoResult(_bck_er, bck_res[algo+'(bAs)'].sdev, _bck_zeros, _bck_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d68cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualization in swath L1X geometry\n",
    "for alg in (algo + '(bAs)', sharpener, algo + '(blur)', algo + '(delta)', algo):\n",
    "    cmap = cmocean.cm.ice\n",
    "    ucmap = cmocean.cm.thermal\n",
    "    vmin, vmax = (0, 1)\n",
    "    umin, umax = (0, 10)\n",
    "    if 'delta' in alg:\n",
    "        cmap = cmocean.cm.balance\n",
    "        ucmap = cmap\n",
    "        vmin, vmax = (-0.3, 0.3)\n",
    "        umin, umax = (vmin, vmax)\n",
    "    fig = plt.figure(figsize=(30,16))\n",
    "    axF = fig.add_subplot(1,4,1)\n",
    "    cF = axF.imshow(fwd_res[alg].sic, vmin=vmin, vmax=vmax, interpolation = 'none', origin='lower', cmap=cmap)\n",
    "    axF.set_title(alg + \" \" + \"FWD\" + \" \" + \"SIC\")\n",
    "    plt.colorbar(cF,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1,4,2, sharex=axF, sharey=axF)\n",
    "    uF = ax.imshow(fwd_res[alg].sdev, vmin=umin, vmax=umax, interpolation = 'none', origin='lower', cmap=ucmap)\n",
    "    ax.set_title(alg + \" \" + \"FWD\" + \" \" + \"SDEV\")\n",
    "    plt.colorbar(uF,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n",
    "    axB = fig.add_subplot(1,4,3)\n",
    "    cB = axB.imshow(bck_res[alg].sic, vmin=vmin, vmax=vmax, interpolation = 'none', origin='lower', cmap=cmap)\n",
    "    axB.set_title(alg + \" \" + \"BCK\" + \" \" + \"SIC\")\n",
    "    plt.colorbar(cB,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1,4,4, sharex=axB, sharey=axB)\n",
    "    uB=ax.imshow(bck_res[alg].sdev, vmin=umin, vmax=umax, interpolation = 'none', origin='lower', cmap=ucmap)\n",
    "    ax.set_title(alg + \" \" + \"BCK\" + \" \" + \"SDEV\")\n",
    "    plt.colorbar(uB,orientation='horizontal', pad=0.05)\n",
    "    #ax.set_xticks([]); ax.set_yticks([])\n",
    "    \n",
    "    axF.set_xlim(400,600)\n",
    "    axF.set_ylim(25,200)\n",
    "    axB.set_xlim(350,550)\n",
    "    axB.set_ylim(325,500)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e6746",
   "metadata": {},
   "source": [
    "## Step 4 : Combine forward and backward scans\n",
    "\n",
    "TODO\n",
    "\n",
    "## Step 5: Write Level-2 product file\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
